{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE351 Quiz 4\n",
    "## Time 40 minutes\n",
    "\n",
    "### Complete the quiz in this jupyter file and submit .\n",
    "\n",
    "\n",
    "\n",
    "You are given 70,000 images (each image consists of 28*28 pixels) of hand-written digits from 0-9.\n",
    "The task is to design a classifier that can recognize these images. In other words, you input an image from this dataset and the output is a predicted number from 0 to 9.\n",
    "\n",
    "For this problem, we only focus on classification task between two digits: 3, and 8, meaning that you deal with a binary classification task. ** If you trian the classifier for all digits you won't ger any credit.**\n",
    "\n",
    "\n",
    "The dataset contains 60,000 images for training and 10,000 for test. \n",
    "Do the following:\n",
    "1. Extract all images contaning digits 3 and 8 both in training and test data set.\n",
    "2.\tPlot an image of the digit 3  and an image of digit 8 from the training data. It could be any image of digit 3 or 8.\n",
    "3.\tTrain a feedforward neural network with the following architecture: \n",
    "    - Three layers\n",
    "    -\t256 hidden units\n",
    "    -\tfeedforward\n",
    "    -   number of epoch = 10\n",
    "4.\tPrint out the accuracy of your model for each epoch both for the test and train sets\n",
    "5.\tReport the classification results using a confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the array is =  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Here are othe required libraries. You are welconme to add more if you need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn import datasets\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# This function loads the images and their labels.  The loading time should be around 4 seconds.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "print(\"the array is = \",x_train.shape)\n",
    "# this would print out : the array is =  (60000, 28, 28) meaning you have 60,000 images and each image is 28 by 28 images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :\n",
    "1. The training dataset contains all the training images in the array format as X(`train_x`) and all the labels are there in `train_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image showing Digit : 2 is present in x_train[5]\n",
      "Image showing Digit : 0 is present in x_train[1]\n"
     ]
    }
   ],
   "source": [
    "# Lets explore what is there in train_y\n",
    "print(\"Image showing Digit : {} is present in x_train[{}]\".format(y_train[5],5))\n",
    "print(\"Image showing Digit : {} is present in x_train[{}]\".format(y_train[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f65430b1d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(y_train[1])\n",
    "plt.imshow(x_train[3].reshape(28, 28))\n",
    "# print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f654364940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1].reshape(28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TA Comments\n",
    "# I am posting the solution with the use of Keras framework here\n",
    "# I will post version from lecture slide 14 later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(x_train.shape)? (<ipython-input-26-e45311219858>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-e45311219858>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print x_train.shape\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(x_train.shape)?\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.1 Extract all images contaning digits 3 and 8 both in training \n",
    "#     and test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[y_test==3.0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_digit_3_train_x = x_train[y_train==3.0]\n",
    "only_digit_3_train_y = y_train[y_train==3.0]\n",
    "only_digit_3_test_x = x_test[y_test==3.0]\n",
    "only_digit_3_test_y = y_test[y_test==3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_digit_8_train_x = x_train[y_train==8.0]\n",
    "only_digit_8_train_y = y_train[y_train==8.0]\n",
    "only_digit_8_test_x = x_test[y_test==8.0]\n",
    "only_digit_8_test_y = y_test[y_test==8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6131, 28, 28), (1010, 28, 28))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_digit_3_train_x.shape,only_digit_3_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5851, 28, 28), (974, 28, 28))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_digit_8_train_x.shape,only_digit_8_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11982"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6131+5851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1010+974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert only_digit_8_train_x.shape[0]==5851\n",
    "assert only_digit_8_test_x.shape[0]==974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert only_digit_3_train_x.shape[0]==6131\n",
    "assert only_digit_3_test_x.shape[0]==1010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.2 Plot an image of the digit 3 and an image of digit 8 from the training data. \n",
    "# It could be any image of digit 3 or 8.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f6543c84e0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANY RANDOM INDEX --> 33\n",
    "plt.imshow(only_digit_3_train_x[33].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f654d29a90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANY RANDOM INDEX --> 14\n",
    "plt.imshow(only_digit_8_train_x[14].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3. Important\n",
    "For this problem, we only focus on classification task between two digits: 3, and 8, meaning that you deal with a binary classification task. \n",
    "**If you train the classifier for all digits you won't ger any credit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 [Continued]\n",
    "3.\tTrain a feedforward neural network with the following architecture: \n",
    "    - Three layers\n",
    "    -\t256 hidden units\n",
    "    -\tfeedforward\n",
    "    -   number of epoch = 10\n",
    "4.\tPrint out the accuracy of your model for each epoch both for the test and train sets\n",
    "5.\tReport the classification results using a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11982"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_digit_3_train_x.shape[0]+only_digit_8_train_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11982, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([only_digit_3_train_x,only_digit_8_train_x]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = np.concatenate([only_digit_3_train_x,\n",
    "                               only_digit_8_train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y = np.concatenate([only_digit_3_train_y,\n",
    "                               only_digit_8_train_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = np.concatenate([only_digit_3_test_x,\n",
    "                              only_digit_8_test_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y = np.concatenate([only_digit_3_test_y,\n",
    "                               only_digit_8_test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape (11982, 28, 28)\n",
      "Train Y Shape (11982,)\n",
      "Test X Shape (1984, 28, 28)\n",
      "Test Y Shape (1984,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X Shape\",train_data_x.shape)\n",
    "print(\"Train Y Shape\",train_data_y.shape)\n",
    "print(\"Test X Shape\",test_data_x.shape)\n",
    "print(\"Test Y Shape\",test_data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using keras framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = train_data_x/255.0\n",
    "test_data_x = test_data_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y = np_utils.to_categorical(train_data_y)\n",
    "test_data_y = np_utils.to_categorical(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11982, 28, 28), (1984, 28, 28))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x.shape,test_data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11982, 9, 2), (1984, 9, 2))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y.shape,test_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(train_data_y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "                    loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=0)\n",
    "        print(\"=-------=\")\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "        print(\"=-------=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = [np.argmax(y, axis=None, out=None) for y in test_data_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_classes\n",
    "test_data_x.reshape(test_data_x.shape[0], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have 2 dimensions, but got array with shape (11982, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-5690842ad05c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(train_data_x, train_data_y, \n\u001b[0;32m      2\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTestCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m          epochs=10, shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have 2 dimensions, but got array with shape (11982, 28, 28)"
     ]
    }
   ],
   "source": [
    "model.fit(train_data_x, train_data_y, \n",
    "          callbacks=[TestCallback((test_data_x, test_data_y))],\n",
    "         epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the classification results using a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3818317e-05, 2.2985789e-05, 1.9408953e-05, ..., 1.8835424e-05,\n",
       "        2.1528545e-05, 5.2566153e-01],\n",
       "       [1.5843275e-06, 1.7403155e-06, 1.3283305e-06, ..., 1.1881012e-06,\n",
       "        1.5057757e-06, 5.3227943e-01],\n",
       "       [1.8159836e-04, 1.7971262e-04, 1.5987820e-04, ..., 1.4721396e-04,\n",
       "        1.6415560e-04, 5.0433964e-01],\n",
       "       ...,\n",
       "       [1.1331223e-05, 9.7221573e-06, 8.8735096e-06, ..., 7.9101965e-06,\n",
       "        1.0900820e-05, 6.9226199e-01],\n",
       "       [3.8198434e-23, 5.2805335e-24, 1.5462557e-23, ..., 5.0594643e-24,\n",
       "        1.5012973e-23, 9.9999976e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_categorical(input_data):\n",
    "    return [np.argmax(y, axis=None, out=None) for y in input_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[713, 297],\n",
       "       [244, 730]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "test_data_x, test_data_y\n",
    "confusion_matrix(reverse_categorical(test_data_y), \n",
    "                 reverse_categorical(model.predict(test_data_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hint: use the code for the training  and the test of  feedforward neural networks in lecture slides 14. You need to chage  that code for these dataset.\n",
    "# Ignore warning if you get any\n",
    "# When we run your code it should print the accuracy for each epoch and one confusion matrix for the  final  epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ConfusionMatrix\\narray([[713, 297],\\n       [244, 730]])\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"ConfusionMatrix\n",
    "array([[713, 297],\n",
    "       [244, 730]])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End\n",
    "import pandas_ml as pdml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
